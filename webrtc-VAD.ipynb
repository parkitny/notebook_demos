{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88693a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it on Binder: https://mybinder.org/v2/gh/parkitny/notebook_demos/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e75274",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://media1.vocaroo.com/mp3/1n5KKFJs9A8n'\n",
    "start_ms = 100000\n",
    "duration_minutes = 1 # minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d073cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import audiosegment\n",
    "import librosa\n",
    "import struct\n",
    "import webrtcvad\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from helpers.audio import audiosegment_to_librosawav\n",
    "from helpers.misc import suppress_stdout_stderr\n",
    "from helpers.webrtc_vad import read_wave, frame_generator, vad_collector, write_wave\n",
    "\n",
    "duration_ms = int(duration_minutes * 60 * 1000) # ms\n",
    "input_filename = \"notebook_data/tmp.mp3\"\n",
    "resampled_filename = \"notebook_data/tmp.wav\"\n",
    "resampled_filename_mp3 = \"notebook_data/tmp.mp3\" \n",
    "Path(input_filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "Path(input_filename).write_bytes(urlopen(url).read())\n",
    "audio = audiosegment.from_file(input_filename)[start_ms: start_ms + duration_ms]\n",
    "audio.export(resampled_filename_mp3, format=\"mp3\")\n",
    "sample_rate = audio.frame_rate\n",
    "samples = audiosegment_to_librosawav(audio)\n",
    "\n",
    "new_sample_rate = 16000\n",
    "samples = librosa.resample(samples, sample_rate, new_sample_rate)\n",
    "sample_rate = new_sample_rate\n",
    "sf.write(resampled_filename, samples, sample_rate)\n",
    "sample_rate, samples = wavfile.read(resampled_filename)\n",
    "vad = webrtcvad.Vad()\n",
    "\n",
    "# set aggressiveness from 0 to 3\n",
    "mode = 3\n",
    "vad.set_mode(mode)\n",
    "raw_samples = struct.pack(\"%dh\" % len(samples), *samples)\n",
    "audio, sample_rate = read_wave(resampled_filename)\n",
    "\n",
    "vad = webrtcvad.Vad(mode)\n",
    "frames = frame_generator(30, audio, sample_rate)\n",
    "frames = list(frames)\n",
    "segments = vad_collector(sample_rate, 30, 300, vad, frames)\n",
    "\n",
    "with suppress_stdout_stderr():\n",
    "    for i, segment in enumerate(list(segments)):\n",
    "        path = 'chunk-{i:02}.wav'\n",
    "        write_wave(path, segment, sample_rate)\n",
    "\n",
    "window_duration = 0.03 # duration in seconds\n",
    "samples_per_window = int(window_duration * sample_rate + 0.5)\n",
    "bytes_per_sample = 2\n",
    "segments = []\n",
    "\n",
    "for start in np.arange(0, len(samples), samples_per_window):\n",
    "    stop = min(start + samples_per_window, len(samples))\n",
    "    \n",
    "    is_speech = vad.is_speech(raw_samples[start * bytes_per_sample: stop * bytes_per_sample], \n",
    "                              sample_rate = sample_rate)\n",
    "\n",
    "    segments.append(dict(\n",
    "       start = start,\n",
    "       stop = stop,\n",
    "       is_speech = is_speech))\n",
    "    \n",
    "fig = plt.figure(figsize = (10,7))\n",
    "ax = plt.gca()\n",
    "ax.plot(samples)\n",
    "\n",
    "ymax = max(samples)\n",
    "\n",
    "## plot segment identifed as speech\n",
    "x = np.array([])\n",
    "y = np.array([])\n",
    "label = np.zeros(len(samples), dtype=int)\n",
    "recs = []\n",
    "\n",
    "ax = fig.axes[0]\n",
    "for segment in segments:\n",
    "    if segment['is_speech']:\n",
    "        label[segment['start'] : segment['stop'] - 1] = 1\n",
    "        ax.add_patch(Rectangle((segment['start'], ymax), segment['stop'] - 1 - segment['start'] , 2000, edgecolor = 'orange',facecolor = 'orange',fill=True, zorder=3))\n",
    "for r in recs:\n",
    "    ax.add_patch(r)\n",
    "plt.xlabel('sample')\n",
    "plt.grid()\n",
    "plt.savefig('tmp.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfe5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ui.audio_player import get_audio_player\n",
    "\n",
    "with open(input_filename, 'rb') as f:\n",
    "    data = f.read()\n",
    "speech_segments = [s for s in segments if s['is_speech']]\n",
    "speech_segments = [(float(s['start']) / sample_rate, float(s['stop']) / sample_rate) for s in speech_segments]\n",
    "\n",
    "audio_player = get_audio_player(data=bytearray(data), speech_segments=speech_segments)\n",
    "audio_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9c2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
